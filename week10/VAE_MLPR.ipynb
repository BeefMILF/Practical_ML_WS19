{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "VAE_MLPR.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.5"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ccc-frankfurt/Practical_ML_WS19/blob/master/week10/VAE_MLPR.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XxZXfBj-ZwXG",
        "colab_type": "text"
      },
      "source": [
        "# Variational Autoencoders\n",
        "Here, we extend our previous MLP and CNN PyTorch Fashion-MNIST autoencoder example to variational autoencoders and thus generative models. \n",
        "\n",
        "Before starting the notebook you should make sure that your runtime uses GPU acceleration. You can find the corresponding option under *runtime* and then *change runtime type*."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7p-P51_uaXIi",
        "colab_type": "code",
        "outputId": "51f1d275-74cf-4806-b16b-c3ed24963a59",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "import numpy as np\n",
        "import math\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torchvision\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline\n",
        "print(torch.__version__)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "1.3.1\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "collapsed": true,
        "id": "NB7ZruPuZwXH",
        "colab_type": "text"
      },
      "source": [
        "### Dataset class in PyTorch\n",
        "Our dataset loader essentially remains the same as before. We do not remove the labels to avoid changes to the code, but they are no longer necessary and we will not use them."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9UhzkhiZZwXI",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import os\n",
        "import struct\n",
        "import gzip\n",
        "import errno\n",
        "import torch.utils.data\n",
        "import torchvision.datasets as datasets\n",
        "\n",
        "\n",
        "class FashionMNIST:\n",
        "    \"\"\"\n",
        "    Fashion MNIST dataset featuring gray-scale 28x28 images of\n",
        "    fashion items belonging to ten different classes.\n",
        "    Dataloader adapted from MNIST.\n",
        "    We do not define __getitem__ and __len__ in this class\n",
        "    as we are using torch.utils.data.TensorDataSet which\n",
        "    already implements these methods.\n",
        "\n",
        "    Parameters:\n",
        "        args (dict): Dictionary of (command line) arguments.\n",
        "            Needs to contain batch_size (int) and workers(int).\n",
        "        is_gpu (bool): True if CUDA is enabled.\n",
        "            Sets value of pin_memory in DataLoader.\n",
        "\n",
        "    Attributes:\n",
        "        trainset (torch.utils.data.TensorDataset): Training set wrapper.\n",
        "        valset (torch.utils.data.TensorDataset): Validation set wrapper.\n",
        "        train_loader (torch.utils.data.DataLoader): Training set loader with shuffling.\n",
        "        val_loader (torch.utils.data.DataLoader): Validation set loader.\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, is_gpu, batch_size, workers):\n",
        "        self.path = os.path.expanduser('datasets/FashionMNIST')\n",
        "        self.__download()\n",
        "\n",
        "        self.trainset, self.valset = self.get_dataset()\n",
        "\n",
        "        self.train_loader, self.val_loader = self.get_dataset_loader(batch_size, workers, is_gpu)\n",
        "\n",
        "        self.val_loader.dataset.class_to_idx = {'T-shirt/top': 0,\n",
        "                                                'Trouser': 1,\n",
        "                                                'Pullover': 2,\n",
        "                                                'Dress': 3,\n",
        "                                                'Coat': 4,\n",
        "                                                'Sandal': 5,\n",
        "                                                'Shirt': 6,\n",
        "                                                'Sneaker': 7,\n",
        "                                                'Bag': 8,\n",
        "                                                'Ankle boot': 9}\n",
        "\n",
        "    def __check_exists(self):\n",
        "        \"\"\"\n",
        "        Checks if dataset has already been downloaded\n",
        "\n",
        "        Returns:\n",
        "             bool: True if downloaded dataset has been found\n",
        "        \"\"\"\n",
        "\n",
        "        return os.path.exists(os.path.join(self.path, 'train-images-idx3-ubyte.gz')) and \\\n",
        "               os.path.exists(os.path.join(self.path, 'train-labels-idx1-ubyte.gz')) and \\\n",
        "               os.path.exists(os.path.join(self.path, 't10k-images-idx3-ubyte.gz')) and \\\n",
        "               os.path.exists(os.path.join(self.path, 't10k-labels-idx1-ubyte.gz'))\n",
        "\n",
        "    def __download(self):\n",
        "        \"\"\"\n",
        "        Downloads the Fashion-MNIST dataset from the web if dataset\n",
        "        hasn't already been downloaded.\n",
        "        \"\"\"\n",
        "\n",
        "        from six.moves import urllib\n",
        "\n",
        "        if self.__check_exists():\n",
        "            return\n",
        "\n",
        "        print(\"Downloading FashionMNIST dataset\")\n",
        "        urls = [\n",
        "            'https://cdn.rawgit.com/zalandoresearch/fashion-mnist/ed8e4f3b/data/fashion/train-images-idx3-ubyte.gz',\n",
        "            'https://cdn.rawgit.com/zalandoresearch/fashion-mnist/ed8e4f3b/data/fashion/train-labels-idx1-ubyte.gz',\n",
        "            'https://cdn.rawgit.com/zalandoresearch/fashion-mnist/ed8e4f3b/data/fashion/t10k-images-idx3-ubyte.gz',\n",
        "            'https://cdn.rawgit.com/zalandoresearch/fashion-mnist/ed8e4f3b/data/fashion/t10k-labels-idx1-ubyte.gz',\n",
        "        ]\n",
        "\n",
        "        # download files\n",
        "        try:\n",
        "            os.makedirs(self.path)\n",
        "        except OSError as e:\n",
        "            if e.errno == errno.EEXIST:\n",
        "                pass\n",
        "            else:\n",
        "                raise\n",
        "\n",
        "        for url in urls:\n",
        "            print('Downloading ' + url)\n",
        "            data = urllib.request.urlopen(url)\n",
        "            filename = url.rpartition('/')[2]\n",
        "            file_path = os.path.join(self.path, filename)\n",
        "            with open(file_path, 'wb') as f:\n",
        "                f.write(data.read())\n",
        "\n",
        "        print('Done!')\n",
        "\n",
        "    def __get_fashion_mnist(self, path, kind='train'):\n",
        "        \"\"\"\n",
        "        Load Fashion-MNIST data\n",
        "\n",
        "        Parameters:\n",
        "            path (str): Base directory path containing .gz files for\n",
        "                the Fashion-MNIST dataset\n",
        "            kind (str): Accepted types are 'train' and 't10k' for\n",
        "                training and validation set stored in .gz files\n",
        "\n",
        "        Returns:\n",
        "            numpy.array: images, labels\n",
        "        \"\"\"\n",
        "\n",
        "        labels_path = os.path.join(path,\n",
        "                                   '%s-labels-idx1-ubyte.gz'\n",
        "                                   % kind)\n",
        "        images_path = os.path.join(path,\n",
        "                                   '%s-images-idx3-ubyte.gz'\n",
        "                                   % kind)\n",
        "\n",
        "        with gzip.open(labels_path, 'rb') as lbpath:\n",
        "            struct.unpack('>II', lbpath.read(8))\n",
        "            labels = np.frombuffer(lbpath.read(), dtype=np.uint8)\n",
        "\n",
        "        with gzip.open(images_path, 'rb') as imgpath:\n",
        "            struct.unpack(\">IIII\", imgpath.read(16))\n",
        "            images = np.frombuffer(imgpath.read(), dtype=np.uint8).reshape(len(labels), 784)\n",
        "\n",
        "        return images, labels\n",
        "\n",
        "    def get_dataset(self):\n",
        "        \"\"\"\n",
        "        Loads and wraps training and validation datasets\n",
        "\n",
        "        Returns:\n",
        "             torch.utils.data.TensorDataset: trainset, valset\n",
        "        \"\"\"\n",
        "\n",
        "        x_train, y_train = self.__get_fashion_mnist(self.path, kind='train')\n",
        "        x_val, y_val = self.__get_fashion_mnist(self.path, kind='t10k')\n",
        "\n",
        "        # This is new with respect to our previous data loader\n",
        "        # convert to torch tensors in range [0, 1]\n",
        "        x_train = torch.from_numpy(x_train).float() / 255\n",
        "        y_train = torch.from_numpy(y_train).long()\n",
        "        x_val = torch.from_numpy(x_val).float() / 255\n",
        "        y_val = torch.from_numpy(y_val).long()\n",
        "\n",
        "        # resize flattened array of images for input to a CNN\n",
        "        # we use the in-place variant of the resize function here\n",
        "        x_train.resize_(x_train.size(0), 1, 28, 28)\n",
        "        x_val.resize_(x_val.size(0), 1, 28, 28)\n",
        "\n",
        "        # TensorDataset wrapper\n",
        "        trainset = torch.utils.data.TensorDataset(x_train, y_train)\n",
        "        valset = torch.utils.data.TensorDataset(x_val, y_val)\n",
        "\n",
        "        return trainset, valset\n",
        "\n",
        "    def get_dataset_loader(self, batch_size, workers, is_gpu):\n",
        "        \"\"\"\n",
        "        Defines the dataset loader for wrapped dataset\n",
        "\n",
        "        Parameters:\n",
        "            batch_size (int): Defines the batch size in data loader\n",
        "            workers (int): Number of parallel threads to be used by data loader\n",
        "            is_gpu (bool): True if CUDA is enabled so pin_memory is set to True\n",
        "\n",
        "        Returns:\n",
        "             torch.utils.data.TensorDataset: trainset, valset\n",
        "        \"\"\"\n",
        "\n",
        "        # multi-threaded data loaders\n",
        "        train_loader = torch.utils.data.DataLoader(self.trainset, batch_size=batch_size, shuffle=True,\n",
        "                                                   num_workers=workers, pin_memory=is_gpu, sampler=None)\n",
        "        test_loader = torch.utils.data.DataLoader(self.valset, batch_size=batch_size, shuffle=True,\n",
        "                                                  num_workers=workers, pin_memory=is_gpu, sampler=None)\n",
        "\n",
        "        return train_loader, test_loader\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SuIk7hjj5Xbl",
        "colab_type": "text"
      },
      "source": [
        "Let's load the data and set the device to use. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gIz2xlhpZwXM",
        "colab_type": "code",
        "outputId": "55618901-2c2b-4e0f-b2b8-d574580862b8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "# set a boolean flag that indicates whether a cuda capable GPU is available \n",
        "# we will need this for transferring our tensors to the device and \n",
        "# for persistent memory in the data loader\n",
        "is_gpu = torch.cuda.is_available()\n",
        "print(\"GPU is available:\", is_gpu)\n",
        "print(\"If you are receiving False, try setting your runtime to GPU\")\n",
        "\n",
        "# set the device to cuda if a GPU is available\n",
        "device = torch.device(\"cuda\" if is_gpu else \"cpu\")\n",
        "\n",
        "# in contrast to our MLP from scratch notebook, we need to set the batch size already now\n",
        "# this is because our data loader now requires it.\n",
        "batch_size = 128\n",
        "# we also set the amount of workers, i.e. parallel threads to use in our data loader\n",
        "workers = 4\n",
        "\n",
        "# We can now instantiate our dataset class \n",
        "dataset = FashionMNIST(is_gpu, batch_size, workers)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "GPU is available: True\n",
            "If you are receiving False, try setting your runtime to GPU\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "collapsed": true,
        "id": "kldGeVaXZwXo",
        "colab_type": "text"
      },
      "source": [
        "# Variational Autoencoder\n",
        "We have seen how we can encode data into a latent vector and decode back to the original image for training with reconstruction loss.  \n",
        "\n",
        "In the lecture we have encountered another Bayesian variant, called the variational autoencoder that provides a different perspective with a powerful generative model: https://arxiv.org/abs/1312.6114 . \n",
        "We will now minimize the variational lower bound on the evidence (ELBO). To approximate the true posterior to the generative model p(x, z) we will use our neural network encoder to calculate q(x|z) (the approximate posterior). This is sometimes also referred to as the recognition model.\n",
        "\n",
        "The probabilistic decoder p(x|z) in turn computes the probability density of an input x under the generative model given a sample z from the approximate posterior q(z|x). Like in the autoencoder the parameters of encoder and decoder are optimized jointly. \n",
        "\n",
        "We can conduct this optimization using the reparameterization trick, where we express the random variable z through a deterministic variable as seen in the lecture.\n",
        "\n",
        "In practical terms, in contrast to the regular autoencoder, we thus now optimize for both a reconstruction loss and KL divergence between our prior and approximate posterior. \n",
        "\n",
        "Following the lecture, we will use a Gaussian prior and implement the corresponding reparameterization.\n",
        "\n",
        "A good in-depth introduction to variational auto-encoders for further reading can be found here: https://arxiv.org/abs/1906.02691\n",
        "\n",
        "## Building our CNN model\n",
        "Last week we have implemented our PyTorch models with nn.Sequential() containers in order to easily access the model.encoder to train a classifier on top. Prior to that we have seen how we can define our model's layers in the class' constructor and use a forward function to define the execution. This week we will encounter another third variant, where we define multiple custom functions called encode, decode and reparameterize which we can then individually access and define a joint forward function. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "I4bPPd5uZwXo",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class VAE_CNN(nn.Module):\n",
        "    def __init__(self, latent_dim):\n",
        "        super(VAE_CNN, self).__init__()\n",
        "        \n",
        "        self.latent_dim = latent_dim \n",
        "        \n",
        "        self.conv1 = nn.Conv2d(1, 64, 5) # input features, output features, kernel size\n",
        "        self.mp1 = nn.MaxPool2d(2, 2) # kernel size, stride\n",
        "        \n",
        "        self.conv2 = nn.Conv2d(64, 128, 5) # input features, output features, kernel size\n",
        "        self.mp2 = nn.MaxPool2d(2, 2) # kernel size, stride\n",
        "        \n",
        "        # tip: 4x4 is the remaining spatial resolution here\n",
        "        self.latent_mu = ...\n",
        "        self.latent_sigma = ...\n",
        "        \n",
        "        # decoder layers\n",
        "        # implement the decoder layers \n",
        "        ...\n",
        "        self.Upsample = nn.Upsample(scale_factor=2, mode='nearest')\n",
        "        \n",
        "    def encode(self, x):\n",
        "        # define the probabilistic encoding\n",
        "        ...\n",
        "        return mu, sigma\n",
        "        \n",
        "    def reparameterize(self, mu, std):\n",
        "        # define the reparameterization: z = eps * sigma + mu\n",
        "        # where eps ~ N(0, 1)\n",
        "        ...\n",
        "        return z\n",
        "    \n",
        "    def decode(self, z):\n",
        "        # define the probabilistic decoding\n",
        "        ...\n",
        "        return x\n",
        "    \n",
        "    def forward(self, x):\n",
        "        # define the end-to-end forward function\n",
        "        ...\n",
        "\n",
        "        # make sure to return output, was well as latent mu and sigma to \n",
        "        # calculate the reconstruction and KLD loss terms\n",
        "        return x, mu, sigma"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9akKD_1ZugZM",
        "colab_type": "text"
      },
      "source": [
        "#### We will now also have to define our loss function\n",
        "In addition to the reconstruction loss, we need to implement the KL divergence between the approximate posterior, thus our latent mu and sigma and our unit Gaussian prior. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "P4YsrK1Kw9JQ",
        "colab_type": "text"
      },
      "source": [
        "We again add a convenience class to log our losses"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ajy_8OckZwXX",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class AverageMeter(object):\n",
        "    \"\"\"\n",
        "    Computes and stores the average and current value\n",
        "    \"\"\"\n",
        "    def __init__(self):\n",
        "        self.reset()\n",
        "\n",
        "    def reset(self):\n",
        "        self.val = 0\n",
        "        self.avg = 0\n",
        "        self.sum = 0\n",
        "        self.count = 0\n",
        "\n",
        "    def update(self, val, n=1):\n",
        "        self.val = val\n",
        "        self.sum += val * n\n",
        "        self.count += n\n",
        "        self.avg = self.sum / self.count"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ApKbVEfUxGW8",
        "colab_type": "text"
      },
      "source": [
        "and the extended loss function"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "s1whWZ3yufsx",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def VAE_loss_function(output, target, mu, std):\n",
        "    recon_loss_func = nn.BCEWithLogitsLoss(reduction='sum')\n",
        "\n",
        "    # compute reconstruction loss - normalize by batch size\n",
        "    recon_loss = ...\n",
        "    \n",
        "    # numerical value for stability of log computation\n",
        "    eps = 1e-8\n",
        "    # compute Kullback Leibler Divergence - normalize by batch size\n",
        "    kld = ...\n",
        "    \n",
        "    return recon_loss, kld"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QHAXq3-0wJvV",
        "colab_type": "text"
      },
      "source": [
        "We will also need to modify our training and validation functions to include the modified loss and let the model return our latent mu and sigma vectors"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gokkqtg6wI1L",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def train(train_loader, model, criterion, optimizer, device):\n",
        "    \"\"\"\n",
        "    Trains/updates the model for one epoch on the training dataset.\n",
        "\n",
        "    Parameters:\n",
        "        train_loader (torch.utils.data.DataLoader): The trainset dataloader\n",
        "        model (torch.nn.module): Model to be trained\n",
        "        criterion (torch.nn.criterion): Loss function\n",
        "        optimizer (torch.optim.optimizer): optimizer instance like SGD or Adam\n",
        "        device (string): cuda or cpu\n",
        "    \"\"\"\n",
        "\n",
        "    # create an instance of the average meter to track losses\n",
        "    losses = AverageMeter()\n",
        "    recon_losses = AverageMeter()\n",
        "    kl_losses = AverageMeter()\n",
        "\n",
        "    # switch to train mode\n",
        "    model.train()\n",
        "\n",
        "    # iterate through the dataset loader\n",
        "    # we can now discard the labels returned by our old data loader as we no longer need them\n",
        "    for i, (inp, _) in enumerate(train_loader):\n",
        "        # transfer inputs and targets to the GPU (if it is available)\n",
        "        inp = inp.to(device)\n",
        "        target = inp\n",
        "        \n",
        "        # you can make your autoencoder a denoising autoencoder by \n",
        "        # adding noise to the input, but not to the target!\n",
        "        # To test the denoising autoencoder, uncomment the line below, \n",
        "        # where we add a small Gaussian noise to the original images\n",
        "        #inp = inp + torch.randn(inp.size()).to(device) * 0.1\n",
        "        \n",
        "        # compute output, i.e. the model forward. \n",
        "        # In contrast to our autoencoder this now also returns the latent mu\n",
        "        # and sigma that we need to calculate the KL divergence\n",
        "        ... = model(...)\n",
        "        \n",
        "        # calculate the loss\n",
        "        recon_loss, kl_loss = criterion(...)\n",
        "        loss = ...\n",
        "\n",
        "        # record loss\n",
        "        losses.update(loss.item(), inp.size(0))\n",
        "        recon_losses.update(recon_loss.item(), inp.size(0))\n",
        "        kl_losses.update(kl_loss.item(), inp.size(0))\n",
        "\n",
        "        # compute gradient and do the SGD step\n",
        "        # we reset the optimizer with zero_grad to \"flush\" former gradients\n",
        "        optimizer.zero_grad()\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        # print the loss every 100 mini-batches\n",
        "        if i % 100 == 0:\n",
        "            print('Loss {loss.val:.4f} ({loss.avg:.4f}) \\t'\n",
        "                  'Reconstruction {recon.val:.4f} ({recon.avg:.4f}) \\t'\n",
        "                  'KLD {kld.val:.4f} ({kld.avg:.4f})'\n",
        "                  .format(loss=losses, recon=recon_losses, kld=kl_losses))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bC3NnwzZW_0A",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def validate(val_loader, model, criterion, device):\n",
        "    \"\"\"\n",
        "    Trains/updates the model for one epoch on the training dataset.\n",
        "\n",
        "    Parameters:\n",
        "        val_loader (torch.utils.data.DataLoader): The valset dataloader\n",
        "        model (torch.nn.module): Model to be trained\n",
        "        criterion (torch.nn.criterion): Loss function\n",
        "        device (string): cuda or cpu\n",
        "    \"\"\"\n",
        "\n",
        "    # create an instance of the average meter to track losses\n",
        "    losses = AverageMeter()\n",
        "    recon_losses = AverageMeter()\n",
        "    kl_losses = AverageMeter()\n",
        "\n",
        "    # switch to train mode\n",
        "    model.eval()\n",
        "\n",
        "    # iterate through the dataset loader\n",
        "    # we can now discard the labels returned by our old data loader as we no longer need them\n",
        "    for i, (inp, _) in enumerate(val_loader):\n",
        "        # transfer inputs and targets to the GPU (if it is available)\n",
        "        inp = inp.to(device)\n",
        "        target = inp\n",
        "        \n",
        "        # compute output, i.e. the model forward. \n",
        "        # In contrast to our autoencoder this now also returns the latent mu\n",
        "        # and sigma that we need to calculate the KL divergence\n",
        "        ... = model(...)\n",
        "        \n",
        "        # calculate the loss\n",
        "        recon_loss, kl_loss = criterion(...)\n",
        "        loss = ...\n",
        "\n",
        "        # record loss\n",
        "        losses.update(loss.item(), inp.size(0))\n",
        "        recon_losses.update(recon_loss.item(), inp.size(0))\n",
        "        kl_losses.update(kl_loss.item(), inp.size(0))\n",
        "        \n",
        "        # print the loss every 100 mini-batches\n",
        "        if i % 100 == 0:\n",
        "            print('Loss {loss.val:.4f} ({loss.avg:.4f}) \\t'\n",
        "                  'Reconstruction {recon.val:.4f} ({recon.avg:.4f}) \\t'\n",
        "                  'KLD {kld.val:.4f} ({kld.avg:.4f})'\n",
        "                  .format(loss=losses, recon=recon_losses, kld=kl_losses))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "daZmD3krcp56",
        "colab_type": "text"
      },
      "source": [
        "In addition to training and validation, we can now also write a generation function. Once the model is training and minimizing the divergence between our approximate posterior distribution and our Gaussian prior, we can start sampling from the prior and directly generate images from the corresponding latent vector z. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7fN8LRKdYX75",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def generate(model, device, num_images=100):\n",
        "    with torch.no_grad():\n",
        "        # sample from the Gaussian prior p(z)\n",
        "        z = ...\n",
        "\n",
        "        # decode the samples p(x|z)\n",
        "        # add a sigmoid function at the end of the decoder to constrain \n",
        "        # the generated image to 0-1 range (which is otherwise not guaranteed)\n",
        "        generated_images = ...\n",
        "\n",
        "        # visualize\n",
        "        imgs = torchvision.utils.make_grid(generated_images.cpu(),\n",
        "                                           nrow=int(math.sqrt(generated_images.size(0))),\n",
        "                                           padding=5)\n",
        "        npimgs = imgs.numpy()\n",
        "        # when using matplotlib the color channels are expected to be in the third \n",
        "        # instead of the first dimension -> tranpose\n",
        "        plt.imshow(np.transpose(npimgs, (1,2,0)))\n",
        "        plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hWBpW7QEZwXq",
        "colab_type": "text"
      },
      "source": [
        "### Constructing and running the CNN based VAE\n",
        "Let's create an instance of our VAE model and optimize it. After each epoch we will sample from the prior and generate some example images and took a look at their visual quality."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9CfyFWGXZwXr",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# create VAE model instance\n",
        "latent_dim = 50 # like in the autoencoder, this is a hyper-parameter\n",
        "# a good starting point for the above model is a latent dimension of 50.\n",
        "model = VAE_CNN(latent_dim).to(device)\n",
        "print(model)\n",
        "\n",
        "# again, define loss function and optimizer. This time using our custom loss.\n",
        "criterion = VAE_loss_function\n",
        "\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=1e-4)\n",
        "\n",
        "# optimize and visualize generations from generative model at each epoch\n",
        "total_epochs = 20\n",
        "for epoch in range(total_epochs):\n",
        "    print(\"EPOCH:\", epoch + 1)\n",
        "    print(\"TRAIN\")\n",
        "    train(dataset.train_loader, model, criterion, optimizer, device)\n",
        "    print(\"VALIDATION\")\n",
        "    validate(dataset.val_loader, model, criterion, device)\n",
        "    print(\"GENERATION\")\n",
        "    generate(model, device, num_images=100)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0iwniQFSZwXu",
        "colab_type": "text"
      },
      "source": [
        "We can see that initially the samples do not look like the data from our training distribution, but after some epochs of optimizing the generative model we are able to generate images by decoding the samples from our Gaussian prior. \n",
        "\n",
        "# Additional exercises\n",
        "\n",
        "1. Use a 2 dimensional latent space and visualize the latent space of the trained model as well as traverse deterministic z values during generation to see how the model interpolates between different concepts. \n",
        "2. Try out last week's pre-training and semi-supervised classification scenarios. Note that as you receive samples z ~ q(z|x) that you now classify p(y|z), you can use multiple samples to get uncertainty estimates! Try to see how this impacts your classification scenario. "
      ]
    }
  ]
}